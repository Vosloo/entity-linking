{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jurek\\anaconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import random\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.kb import KnowledgeBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mapped_data.pkl', 'rb') as handle:\n",
    "    mapped_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = pd.read_csv(\"filtered_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('df_filtered.pickle', 'rb') as handle:\n",
    "#     data_filtered = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv(\"./data/archive/item.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_aliases = pd.read_csv(\"./data/archive/item_aliases.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>en_label</th>\n",
       "      <th>en_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Universe</td>\n",
       "      <td>totality of space and all contents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Earth</td>\n",
       "      <td>third planet from the Sun in the Solar System</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>life</td>\n",
       "      <td>matter capable of extracting energy from the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>death</td>\n",
       "      <td>permanent cessation of vital functions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>human</td>\n",
       "      <td>common name of Homo sapiens, unique extant spe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  en_label                                     en_description\n",
       "0        1  Universe                 totality of space and all contents\n",
       "1        2     Earth      third planet from the Sun in the Solar System\n",
       "2        3      life  matter capable of extracting energy from the e...\n",
       "3        4     death             permanent cessation of vital functions\n",
       "4        5     human  common name of Homo sapiens, unique extant spe..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>en_alias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Our Universe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Universe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>The Cosmos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>cosmos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Blue Planet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id      en_alias\n",
       "0        1  Our Universe\n",
       "1        1  The Universe\n",
       "2        1    The Cosmos\n",
       "3        1        cosmos\n",
       "4        2   Blue Planet"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_aliases.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>en_alias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [item_id, en_alias]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_aliases[items_aliases[\"item_id\"]==188285]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_indexes = set(data_filtered.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_indexes.update(set(data_filtered[\"Work_of_art\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171723"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_items = items[items[\"item_id\"].isin(set_indexes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_aliases = items_aliases[items_aliases[\"item_id\"].isin(set_indexes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_items = filtered_items.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>en_label</th>\n",
       "      <th>en_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1904910</th>\n",
       "      <td>2309609</td>\n",
       "      <td>wayside cross</td>\n",
       "      <td>cross by a footpath, track or road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45023997</th>\n",
       "      <td>66103239</td>\n",
       "      <td>wayside cross</td>\n",
       "      <td>monument in Bechyňská Smoleč, Czechia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45024026</th>\n",
       "      <td>66103270</td>\n",
       "      <td>wayside cross</td>\n",
       "      <td>iron cross between Bechyňská Smoleč and Černýš...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45024112</th>\n",
       "      <td>66103366</td>\n",
       "      <td>wayside cross</td>\n",
       "      <td>monument in the village of Černýšovice, Czechia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45024498</th>\n",
       "      <td>66103780</td>\n",
       "      <td>wayside cross</td>\n",
       "      <td>iron monument remembering 2 drowned people nea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           item_id       en_label  \\\n",
       "1904910    2309609  wayside cross   \n",
       "45023997  66103239  wayside cross   \n",
       "45024026  66103270  wayside cross   \n",
       "45024112  66103366  wayside cross   \n",
       "45024498  66103780  wayside cross   \n",
       "\n",
       "                                             en_description  \n",
       "1904910                  cross by a footpath, track or road  \n",
       "45023997              monument in Bechyňská Smoleč, Czechia  \n",
       "45024026  iron cross between Bechyňská Smoleč and Černýš...  \n",
       "45024112    monument in the village of Černýšovice, Czechia  \n",
       "45024498  iron monument remembering 2 drowned people nea...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_items[filtered_items[\"en_label\"] == \"wayside cross\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupa = filtered_items.reset_index(drop=True).set_index([\"en_label\"]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>en_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wayside cross</th>\n",
       "      <td>66103270</td>\n",
       "      <td>iron cross between Bechyňská Smoleč and Černýš...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wayside cross</th>\n",
       "      <td>2309609</td>\n",
       "      <td>cross by a footpath, track or road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wayside cross</th>\n",
       "      <td>66103366</td>\n",
       "      <td>monument in the village of Černýšovice, Czechia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wayside cross</th>\n",
       "      <td>66103780</td>\n",
       "      <td>iron monument remembering 2 drowned people nea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wayside cross</th>\n",
       "      <td>66103239</td>\n",
       "      <td>monument in Bechyňská Smoleč, Czechia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                item_id                                     en_description\n",
       "en_label                                                                  \n",
       "wayside cross  66103270  iron cross between Bechyňská Smoleč and Černýš...\n",
       "wayside cross   2309609                 cross by a footpath, track or road\n",
       "wayside cross  66103366    monument in the village of Černýšovice, Czechia\n",
       "wayside cross  66103780  iron monument remembering 2 drowned people nea...\n",
       "wayside cross  66103239              monument in Bechyňská Smoleč, Czechia"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupa.loc[\"wayside cross\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 79907 / 79908"
     ]
    }
   ],
   "source": [
    "en_label = pd.unique(filtered_items.en_label)\n",
    "for ind, label in enumerate(en_label):\n",
    "    #filtered_items[filtered_items[\"en_label\"] == label]\n",
    "    print(f\"\\r{ind:6} / 79908\",end=\"\")\n",
    "    dupa.loc[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Work_of_art</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>63412991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>24856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>21198342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7216</th>\n",
       "      <td>11424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67102008</th>\n",
       "      <td>24862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67102980</th>\n",
       "      <td>371752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67103629</th>\n",
       "      <td>11424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67103743</th>\n",
       "      <td>11424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67103944</th>\n",
       "      <td>11424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171140 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Work_of_art\n",
       "qid                  \n",
       "149          63412991\n",
       "844             24856\n",
       "904          21198342\n",
       "1351             1344\n",
       "7216            11424\n",
       "...               ...\n",
       "67102008        24862\n",
       "67102980       371752\n",
       "67103629        11424\n",
       "67103743        11424\n",
       "67103944        11424\n",
       "\n",
       "[171140 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#kb = KnowledgeBase(vocab=nlp.vocab, entity_vector_length=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kb.dump(\"my_kb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "nlp_vectors = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kb(vocab):\n",
    "    kb = KnowledgeBase(vocab=vocab, entity_vector_length=300)\n",
    "    en_label = pd.unique(filtered_items.en_label)\n",
    "    for ind, label in enumerate(en_label):\n",
    "        print(f\"\\r{ind:6} / 79908\",end=\"\")\n",
    "        res = dupa.loc[label]\n",
    "        name = label\n",
    "        if type(res) == pd.Series:\n",
    "            qid = [res.values[0]]\n",
    "            desc = [res.values[1]]\n",
    "        else:\n",
    "            qid = res.values[:,0]\n",
    "            desc = res.values[:,1]\n",
    "\n",
    "        for ind, qid_ in enumerate(qid):\n",
    "            desc_enc = nlp_vectors(desc[ind]).vector\n",
    "            kb.add_entity(entity=str(qid_), entity_vector=desc_enc, freq=342)\n",
    "\n",
    "        probs = [1/len(qid)] * len(qid) if len(qid) > 1 else [1]\n",
    "        try:\n",
    "            kb.add_alias(alias=name, entities=list(map(str, qid)), probabilities=probs)\n",
    "        except Exception as e:\n",
    "            print(name)\n",
    "            print(list(qid))\n",
    "            print(probs)\n",
    "            raise e\n",
    "    return kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 79907 / 79908"
     ]
    }
   ],
   "source": [
    "config={\"incl_prior\":False}\n",
    "entity_linker = nlp.add_pipe(\"entity_linker\", config=config)\n",
    "entity_linker.set_kb(create_kb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "qids = list(set_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_ids = []\n",
    "for text, annot in mapped_data:\n",
    "    for span, links_dict in annot[\"links\"].items():\n",
    "        for link, value in links_dict.items():\n",
    "            if value:\n",
    "                gold_ids.append(link)\n",
    "\n",
    "from collections import Counter\n",
    "#print(Counter(gold_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19092"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(mapped_data)\n",
    "\n",
    "train_data = mapped_data\n",
    "#test_data = mapped_data[18092:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.training import Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DOCS = []\n",
    "if \"sentencizer\" not in nlp.pipe_names:\n",
    "    nlp.add_pipe(\"sentencizer\")\n",
    "sentencizer = nlp.get_pipe(\"sentencizer\")\n",
    "for text, annotation in train_data:\n",
    "    for span, code in annotation[\"links\"].items():\n",
    "        str_id = str(list(code.keys())[0])\n",
    "        new_ann = {\"entities\": [(*span, \"WORK_OF_ART\")]} | {\"links\": {span: {str_id: list(code.values())[0]}}}\n",
    "    try:\n",
    "        example = Example.from_dict(nlp.make_doc(text), new_ann)\n",
    "    except Exception as e:\n",
    "        continue\n",
    "    example.reference = sentencizer(example.reference)\n",
    "    #print(example)\n",
    "    TRAIN_DOCS.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18577"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TRAIN_DOCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_linker.initialize(get_examples=lambda: TRAIN_DOCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.util import minibatch, compounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jurek\\Desktop\\Semantic\\entity-linking\\data_training.ipynb Komórka 36\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jurek/Desktop/Semantic/entity-linking/data_training.ipynb#X54sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m losses \u001b[39m=\u001b[39m {}\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jurek/Desktop/Semantic/entity-linking/data_training.ipynb#X54sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m batches:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Jurek/Desktop/Semantic/entity-linking/data_training.ipynb#X54sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     nlp\u001b[39m.\u001b[39;49mupdate(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jurek/Desktop/Semantic/entity-linking/data_training.ipynb#X54sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         batch,   \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jurek/Desktop/Semantic/entity-linking/data_training.ipynb#X54sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         drop\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,      \u001b[39m# prevent overfitting\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jurek/Desktop/Semantic/entity-linking/data_training.ipynb#X54sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         losses\u001b[39m=\u001b[39;49mlosses,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jurek/Desktop/Semantic/entity-linking/data_training.ipynb#X54sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         sgd\u001b[39m=\u001b[39;49moptimizer,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jurek/Desktop/Semantic/entity-linking/data_training.ipynb#X54sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jurek/Desktop/Semantic/entity-linking/data_training.ipynb#X54sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mif\u001b[39;00m itn \u001b[39m%\u001b[39m \u001b[39m50\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jurek/Desktop/Semantic/entity-linking/data_training.ipynb#X54sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mprint\u001b[39m(itn, \u001b[39m\"\u001b[39m\u001b[39mLosses\u001b[39m\u001b[39m\"\u001b[39m, losses)   \u001b[39m# print the training loss\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jurek\\anaconda3\\envs\\nlp\\lib\\site-packages\\spacy\\language.py:1164\u001b[0m, in \u001b[0;36mLanguage.update\u001b[1;34m(self, examples, _, drop, sgd, losses, component_cfg, exclude, annotates)\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[39mfor\u001b[39;00m name, proc \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpipeline:\n\u001b[0;32m   1162\u001b[0m     \u001b[39m# ignore statements are used here because mypy ignores hasattr\u001b[39;00m\n\u001b[0;32m   1163\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exclude \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mupdate\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1164\u001b[0m         proc\u001b[39m.\u001b[39mupdate(examples, sgd\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, losses\u001b[39m=\u001b[39mlosses, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcomponent_cfg[name])  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m     \u001b[39mif\u001b[39;00m sgd \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m   1166\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1167\u001b[0m             name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exclude\n\u001b[0;32m   1168\u001b[0m             \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(proc, ty\u001b[39m.\u001b[39mTrainableComponent)\n\u001b[0;32m   1169\u001b[0m             \u001b[39mand\u001b[39;00m proc\u001b[39m.\u001b[39mis_trainable\n\u001b[0;32m   1170\u001b[0m             \u001b[39mand\u001b[39;00m proc\u001b[39m.\u001b[39mmodel \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, \u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m   1171\u001b[0m         ):\n",
      "File \u001b[1;32mc:\\Users\\Jurek\\anaconda3\\envs\\nlp\\lib\\site-packages\\spacy\\pipeline\\entity_linker.py:316\u001b[0m, in \u001b[0;36mEntityLinker.update\u001b[1;34m(self, examples, drop, sgd, losses)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[39mfor\u001b[39;00m doc, ex \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(docs, examples):\n\u001b[0;32m    315\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_gold_ents:\n\u001b[1;32m--> 316\u001b[0m         ents, _ \u001b[39m=\u001b[39m ex\u001b[39m.\u001b[39;49mget_aligned_ents_and_ner()\n\u001b[0;32m    317\u001b[0m         doc\u001b[39m.\u001b[39ments \u001b[39m=\u001b[39m ents\n\u001b[0;32m    318\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m         \u001b[39m# only keep matching ents\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with nlp.select_pipes(enable=[\"entity_linker\"]):   # train only the entity_linker\n",
    "    optimizer = nlp.resume_training()\n",
    "    for itn in range(500):   # 500 iterations takes about a minute to train\n",
    "        random.shuffle(TRAIN_DOCS)\n",
    "        batches = minibatch(TRAIN_DOCS, size=compounding(4.0, 32.0, 1.001))  # increasing batch sizes\n",
    "        losses = {}\n",
    "        for batch in batches:\n",
    "            nlp.update(\n",
    "                batch,   \n",
    "                drop=0.2,      # prevent overfitting\n",
    "                losses=losses,\n",
    "                sgd=optimizer,\n",
    "            )\n",
    "        if itn % 50 == 0:\n",
    "            print(itn, \"Losses\", losses)   # print the training loss\n",
    "print(itn, \"Losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>en_label</th>\n",
       "      <th>en_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>174729</th>\n",
       "      <td>188285</td>\n",
       "      <td>motet</td>\n",
       "      <td>choral musical composition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id en_label              en_description\n",
       "174729   188285    motet  choral musical composition"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_items[filtered_items[\"item_id\"]==188285]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'motet'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt = \"The 'Tenebrae Responsories' by Tomás Luis de Victoria are a set of eighteen motets for four voices a cappella. The late Renaissance Spanish composer set the Responsories for Holy Week known as Tenebrae responsories. They are liturgical texts prescribed for use in the Catholic observances during the Triduum of the Holy Week, in the Matins of Maundy Thursday, Good Friday and Holy Saturday. The compositions were published in Rome in 1585. The eighteen Tenebrae Responsories are set for four voices each but with varying disposition of the voices soprano (S), alto (A), tenor (T) and bass (B). Soprano, tenor and bass are at times divided. Six responsories are dedicated to each Matins of Maundy Thursday (\"\", the Lord's supper), Good Friday, and Holy Saturday (\"\"). *\"\n",
    "ttt[76:81]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_linker = nlp.create_pipe(\"entity_linker\", config={\"incl_prior\":False})\n",
    "entity_linker.set_kb(kb)\n",
    "nlp.add_pipe(entity_linker, last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[E188] Could not match the gold entity links to entities in the doc - make sure the gold EL data refers to valid results of the named entity recognizer in the `nlp` pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-a0f6948cbbcc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m      \u001b[1;31m# prevent overfitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[0mlosses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[0msgd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             )\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mitn\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m50\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jurek\\anaconda3\\envs\\Semantic\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, docs, golds, drop, sgd, losses, component_cfg)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomponent_cfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"drop\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgolds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_grads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m                 \u001b[0msgd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpipes.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.pipes.EntityLinker.update\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [E188] Could not match the gold entity links to entities in the doc - make sure the gold EL data refers to valid results of the named entity recognizer in the `nlp` pipeline."
     ]
    }
   ],
   "source": [
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"entity_linker\"]\n",
    "with nlp.disable_pipes(*other_pipes):   # train only the entity_linker\n",
    "    optimizer = nlp.begin_training()\n",
    "    for itn in range(500):   # 500 iterations takes about a minute to train\n",
    "        random.shuffle(TRAIN_DOCS)\n",
    "        batches = minibatch(TRAIN_DOCS, size=compounding(4.0, 32.0, 1.001))  # increasing batch sizes\n",
    "        losses = {}\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(\n",
    "                texts,  \n",
    "                annotations,   \n",
    "                drop=0.2,      # prevent overfitting\n",
    "                losses=losses,\n",
    "                sgd=optimizer,\n",
    "            )\n",
    "        if itn % 50 == 0:\n",
    "            print(itn, \"Losses\", losses)   # print the training loss\n",
    "print(itn, \"Losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[E188] Could not match the gold entity links to entities in the doc - make sure the gold EL data refers to valid results of the named entity recognizer in the `nlp` pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-9f4147c6a7c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[0mlosses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                 \u001b[0msgd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             )\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mif\u001b[0m  \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m50\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jurek\\anaconda3\\envs\\Semantic\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, docs, golds, drop, sgd, losses, component_cfg)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomponent_cfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"drop\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgolds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_grads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m                 \u001b[0msgd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpipes.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.pipes.EntityLinker.update\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [E188] Could not match the gold entity links to entities in the doc - make sure the gold EL data refers to valid results of the named entity recognizer in the `nlp` pipeline."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"entity_linker\"]\n",
    "# with nlp.disable_pipes(*other_pipes):\n",
    "#     optimizer = nlp.begin_training()\n",
    "#     for i in range(500):\n",
    "#         random.shuffle(TRAIN_DOCS)#DOSTOSOWAĆ DANE\n",
    "#         batches = minibatch(TRAIN_DOCS, size=compounding(4.0, 32.0, 1.001))\n",
    "#         losses = {}\n",
    "#         for batch in batches:\n",
    "#             texts, annotations = zip(*batch)\n",
    "#             nlp.update(\n",
    "#                 texts,\n",
    "#                 annotations,\n",
    "#                 drop=0.2,\n",
    "#                 losses=losses,\n",
    "#                 sgd=optimizer\n",
    "#             )\n",
    "#         if  i % 50 == 0:\n",
    "#             print(i, \"Losses\", losses)\n",
    "\n",
    "# nlp.to_disk(\"my_nlp_el\")\n",
    "\n",
    "# with open(\"test_set.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(output_dir / \"my_nlp_el\")\n",
    "text = \"\"\n",
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_, ent.kb_id_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f16bd32f816dc4beb702c0f7768fcd68b994a130f2aec88184ef3612c995104c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
