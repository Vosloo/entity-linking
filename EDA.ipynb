{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import CONLL_03\n",
    "from flair.embeddings import PooledFlairEmbeddings, StackedEmbeddings, TokenEmbeddings, WordEmbeddings\n",
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.datasets import CONLL_03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-04 21:32:44,051 Reading data from data/conll_03\n",
      "2022-12-04 21:32:44,052 Train: data/conll_03/train.txt\n",
      "2022-12-04 21:32:44,052 Dev: data/conll_03/dev.txt\n",
      "2022-12-04 21:32:44,052 Test: data/conll_03/test.txt\n"
     ]
    }
   ],
   "source": [
    "corpus: Corpus = CONLL_03(base_path=DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-04 21:32:49,686 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14987it [00:00, 77287.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-04 21:32:49,882 Dictionary created for label 'ner' with 5 values: LOC (seen 7140 times), PER (seen 6600 times), ORG (seen 6321 times), MISC (seen 3438 times)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-04 21:32:55,779 SequenceTagger predicts: Dictionary with 17 tags: O, S-LOC, B-LOC, E-LOC, I-LOC, S-PER, B-PER, E-PER, I-PER, S-ORG, B-ORG, E-ORG, I-ORG, S-MISC, B-MISC, E-MISC, I-MISC\n",
      "2022-12-04 21:32:56,270 ----------------------------------------------------------------------------------------------------\n",
      "2022-12-04 21:32:56,271 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): PooledFlairEmbeddings(\n",
      "      (context_embeddings): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.05, inplace=False)\n",
      "          (encoder): Embedding(300, 100)\n",
      "          (rnn): LSTM(100, 2048)\n",
      "          (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (list_embedding_2): PooledFlairEmbeddings(\n",
      "      (context_embeddings): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.05, inplace=False)\n",
      "          (encoder): Embedding(300, 100)\n",
      "          (rnn): LSTM(100, 2048)\n",
      "          (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=8292, out_features=8292, bias=True)\n",
      "  (rnn): LSTM(8292, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=19, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-12-04 21:32:56,271 ----------------------------------------------------------------------------------------------------\n",
      "2022-12-04 21:32:56,272 Corpus: \"Corpus: 14987 train + 3466 dev + 3684 test sentences\"\n",
      "2022-12-04 21:32:56,272 ----------------------------------------------------------------------------------------------------\n",
      "2022-12-04 21:32:56,272 Parameters:\n",
      "2022-12-04 21:32:56,273  - learning_rate: \"0.100000\"\n",
      "2022-12-04 21:32:56,274  - mini_batch_size: \"32\"\n",
      "2022-12-04 21:32:56,275  - patience: \"3\"\n",
      "2022-12-04 21:32:56,276  - anneal_factor: \"0.5\"\n",
      "2022-12-04 21:32:56,277  - max_epochs: \"150\"\n",
      "2022-12-04 21:32:56,277  - shuffle: \"True\"\n",
      "2022-12-04 21:32:56,277  - train_with_dev: \"True\"\n",
      "2022-12-04 21:32:56,278  - batch_growth_annealing: \"False\"\n",
      "2022-12-04 21:32:56,278 ----------------------------------------------------------------------------------------------------\n",
      "2022-12-04 21:32:56,278 Model training base path: \"data/taggers/example-ner\"\n",
      "2022-12-04 21:32:56,279 ----------------------------------------------------------------------------------------------------\n",
      "2022-12-04 21:32:56,280 Device: cuda:0\n",
      "2022-12-04 21:32:56,281 ----------------------------------------------------------------------------------------------------\n",
      "2022-12-04 21:32:56,281 Embeddings storage mode: cpu\n",
      "2022-12-04 21:32:56,282 ----------------------------------------------------------------------------------------------------\n",
      "2022-12-04 21:32:56,282 train mode resetting embeddings\n",
      "2022-12-04 21:32:56,282 train mode resetting embeddings\n",
      "2022-12-04 21:33:14,359 epoch 1 - iter 57/577 - loss 0.56854672 - samples/sec: 100.92 - lr: 0.100000\n",
      "2022-12-04 21:33:33,872 epoch 1 - iter 114/577 - loss 0.40069594 - samples/sec: 93.49 - lr: 0.100000\n",
      "2022-12-04 21:33:47,004 epoch 1 - iter 171/577 - loss 0.35069461 - samples/sec: 138.93 - lr: 0.100000\n",
      "2022-12-04 21:34:01,276 epoch 1 - iter 228/577 - loss 0.30989380 - samples/sec: 127.84 - lr: 0.100000\n",
      "2022-12-04 21:34:18,814 epoch 1 - iter 285/577 - loss 0.27252116 - samples/sec: 104.02 - lr: 0.100000\n",
      "2022-12-04 21:34:37,971 epoch 1 - iter 342/577 - loss 0.24676769 - samples/sec: 95.23 - lr: 0.100000\n",
      "2022-12-04 21:34:57,147 epoch 1 - iter 399/577 - loss 0.22891603 - samples/sec: 95.14 - lr: 0.100000\n",
      "2022-12-04 21:35:18,969 epoch 1 - iter 456/577 - loss 0.21132713 - samples/sec: 83.60 - lr: 0.100000\n",
      "2022-12-04 21:35:37,986 epoch 1 - iter 513/577 - loss 0.19829437 - samples/sec: 96.14 - lr: 0.100000\n",
      "2022-12-04 21:35:57,531 epoch 1 - iter 570/577 - loss 0.18948670 - samples/sec: 93.36 - lr: 0.100000\n",
      "2022-12-04 21:36:00,655 ----------------------------------------------------------------------------------------------------\n",
      "2022-12-04 21:36:00,656 EPOCH 1 done: loss 0.1881 - lr 0.100000\n",
      "2022-12-04 21:36:00,656 BAD EPOCHS (no improvement): 0\n",
      "2022-12-04 21:36:00,770 ----------------------------------------------------------------------------------------------------\n",
      "2022-12-04 21:36:01,007 train mode resetting embeddings\n",
      "2022-12-04 21:36:01,012 train mode resetting embeddings\n",
      "2022-12-04 21:36:10,931 epoch 2 - iter 57/577 - loss 0.10537733 - samples/sec: 191.70 - lr: 0.100000\n",
      "2022-12-04 21:36:20,340 epoch 2 - iter 114/577 - loss 0.09691212 - samples/sec: 193.95 - lr: 0.100000\n",
      "2022-12-04 21:36:29,642 epoch 2 - iter 171/577 - loss 0.09468328 - samples/sec: 196.19 - lr: 0.100000\n",
      "2022-12-04 21:36:38,926 epoch 2 - iter 228/577 - loss 0.09295156 - samples/sec: 196.54 - lr: 0.100000\n",
      "2022-12-04 21:36:48,262 epoch 2 - iter 285/577 - loss 0.09030960 - samples/sec: 195.46 - lr: 0.100000\n",
      "2022-12-04 21:36:57,536 epoch 2 - iter 342/577 - loss 0.08764662 - samples/sec: 196.77 - lr: 0.100000\n",
      "2022-12-04 21:37:11,386 epoch 2 - iter 399/577 - loss 0.08752114 - samples/sec: 132.32 - lr: 0.100000\n",
      "2022-12-04 21:37:21,391 epoch 2 - iter 456/577 - loss 0.08666573 - samples/sec: 188.28 - lr: 0.100000\n",
      "2022-12-04 21:37:31,010 epoch 2 - iter 513/577 - loss 0.08520129 - samples/sec: 189.90 - lr: 0.100000\n",
      "2022-12-04 21:37:41,920 epoch 2 - iter 570/577 - loss 0.08392214 - samples/sec: 167.37 - lr: 0.100000\n",
      "2022-12-04 21:37:43,419 ----------------------------------------------------------------------------------------------------\n",
      "2022-12-04 21:37:43,419 EPOCH 2 done: loss 0.0839 - lr 0.100000\n",
      "2022-12-04 21:37:43,420 BAD EPOCHS (no improvement): 0\n",
      "2022-12-04 21:37:43,522 ----------------------------------------------------------------------------------------------------\n",
      "2022-12-04 21:37:43,523 train mode resetting embeddings\n",
      "2022-12-04 21:37:43,611 train mode resetting embeddings\n"
     ]
    }
   ],
   "source": [
    "tag_dictionary = corpus.make_label_dictionary(label_type=\"ner\")\n",
    "\n",
    "embedding_types: list[TokenEmbeddings] = [\n",
    "    WordEmbeddings(\"glove\"),\n",
    "    PooledFlairEmbeddings(\"news-forward\", pooling=\"min\"),\n",
    "    PooledFlairEmbeddings(\"news-backward\", pooling=\"min\"),\n",
    "]\n",
    "\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "\n",
    "tagger: SequenceTagger = SequenceTagger(\n",
    "    hidden_size=256, embeddings=embeddings, tag_dictionary=tag_dictionary, tag_type=\"ner\"\n",
    ")\n",
    "\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "trainer.train(\n",
    "    \"data/taggers/example-ner\",\n",
    "    train_with_dev=True,\n",
    "    num_workers=4,\n",
    "    max_epochs=150,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) \n[GCC 10.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6732d5bcbccbd400c2295e6b9ff4a247e8d1a91ef1c3ef29ad75df96351d9278"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
